{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3ddbf6f-c32d-4e4d-8190-8976c392dbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import MySQLdb\n",
    "import pygrametl\n",
    "from pygrametl.datasources import CSVSource, SQLSource, PandasSource\n",
    "from pygrametl.tables import Dimension, FactTable, SlowlyChangingDimension, TypeOneSlowlyChangingDimension, AccumulatingSnapshotFactTable\n",
    "import duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbaaad68-2b9e-468b-99eb-d4a3c7c36085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computelag(row, namemapping, updated):\n",
    "    \"\"\"The function calculates the difference in days between different events\"\"\"\n",
    "    if 'ship_date' in updated:\n",
    "        row['shipment_lag'] = (row['ship_date'] - row['order_date']).days\n",
    "    if 'delivery_date' in updated:\n",
    "        row['delivery_lag'] = (row['delivery_date'] - row['ship_date']).days\n",
    "\n",
    "\n",
    "def fact_orders_acc(sourceDatabase, dw_conn_wrapper):\n",
    "\n",
    "    # Specify the query that will generate the input dataset  \n",
    "    sql = \"select order_num, employee_id,customer_id,product_id,sales_channel_id,currency_code,cast(order_quantity as DECIMAL(18, 2)) as order_quantity,cast(total_cost as DECIMAL(18, 2)) as total_cost,cast(total_price as DECIMAL(18, 2)) as total_price,cast(order_date as date) as order_date,cast(ship_date as date) as ship_date,cast(delivery_date as date) as delivery_date,cast(procure_date as date) as procure_date from sales_order\"\n",
    "    # Pygrametl will automatically rename columns, in case if names of the input columns are different from the result dataset \n",
    "    name_mapping = 'order_num', 'employee_id','customer_id','product_id','sales_channel_id','currency_code','order_quantity','total_cost','total_price','order_date','ship_date','delivery_date','procure_date'  \n",
    "    source = SQLSource(connection = sourceDatabase, query = sql, names = name_mapping)\n",
    "\n",
    "    \n",
    "    asft = AccumulatingSnapshotFactTable(\n",
    "        name = 'fact_sales_acc',  # name of the fact table in the data warehouse \n",
    "        keyrefs = ['order_num', 'employee_id', 'customer_id', 'product_id', 'sales_channel_id'], # a sequence of attribute names that constitute the primary key of the fact tables \n",
    "        #(i.e., primary keys in the dimension tables that corresponds to foreign keys in the fact table)\n",
    "        otherrefs = ['order_date', 'ship_date', 'delivery_date', 'procure_date'], # date columns that should be updated\n",
    "        measures = ['order_quantity', 'total_cost', 'total_price', 'shipment_lag', 'delivery_lag'], # a list of measures\n",
    "        factexpander = computelag) # calls the computerlag function to computer the lag measures before the row in the fact table is updated\n",
    "\n",
    "    # Lookup the given row. If that fails, insert it. If found, see if values for attributes in otherrefs or measures have changed and update the found row \n",
    "    # if necessary (note that values for attributes in keyrefs are not allowed to change). If an update is necessary and a factexpander is defined, \n",
    "    # the row will first be updated with any missing otherrefs/measures and the factexpander will be run on it.\n",
    "    for row in source:\n",
    "        asft.ensure(row)\n",
    "\n",
    "    dw_conn_wrapper.commit()\n",
    "    dw_conn_wrapper.close()\n",
    "\n",
    "\n",
    "def main():\n",
    "    fact_orders_acc(sourceDatabase, dw_conn_wrapper)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Connect to salesdb (OLTP) and salesdwh (OLT)\n",
    "    sourceDatabase = MySQLdb.connect(database = 'salesdb', user = 'user', password = 'password', port = 42333)\n",
    "    destDatabase = duckdb.connect(r'C:\\Users\\katep\\OneDrive\\Desktop\\DEV-modeling\\assets_scripts\\salesdwh.duckdb') # Change the path if you have your sales duckDB somewhere else\n",
    "    dw_conn_wrapper = pygrametl.ConnectionWrapper(connection = destDatabase)\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d7084d-8a04-40c4-8538-b614a8c5fd0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
