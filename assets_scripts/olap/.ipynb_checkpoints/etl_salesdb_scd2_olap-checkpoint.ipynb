{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2a40bb8-f53e-4bf1-b95a-725a70f9008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import pandas as pd\n",
    "import MySQLdb\n",
    "import pygrametl\n",
    "from pygrametl.datasources import CSVSource, SQLSource, PandasSource\n",
    "from pygrametl.tables import Dimension, FactTable, SlowlyChangingDimension, TypeOneSlowlyChangingDimension, AccumulatingSnapshotFactTable\n",
    "import duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cc85815-f8e5-4a34-aa22-d01e987e82d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#intial data load\n",
    "def dim_employees_scd2(sourceDatabase, dw_conn_wrapper):\n",
    "    \"\"\"The function creates the dimensional table - SCD type 2\"\"\"\n",
    "    # Specify the query that will generate the input dataset   \n",
    "    sql = \"select employee_id, concat(employee_first_name,' ', employee_last_name) as employee_name,store_id from employee\"\n",
    "   # Pygrametl will automatically rename columns, in case if names of the input columns are different from the result dataset \n",
    "    name_mapping = 'employee_id','employee_name','store_id'\n",
    "    source = SQLSource(connection = sourceDatabase, query = sql, names = name_mapping)\n",
    "    employees_dim = SlowlyChangingDimension(\n",
    "        name = 'dim_employee_scd2',  # name of the dimensions table in the data warehouse \n",
    "        key = 'employee_sk', # name of the primary key\n",
    "        attributes = ['employee_id', 'valid_from', 'valid_to', 'version', 'employee_name', 'store_id'], #: a sequence of the attribute names in the dimension table. \n",
    "        # Should not include the name of the primary key which is given in the key argument.\n",
    "        lookupatts = ['employee_id'], # a sequence with a subset of the attributes that uniquely identify a dimension members. \n",
    "        fromatt = 'valid_from', # the name of the attribute telling from when the version becomes valid. Default: None\n",
    "        toatt = 'valid_to',\n",
    "        versionatt = 'version') # the name of the attribute telling until when the version is valid. Default: None\n",
    "\n",
    "    for row in source:\n",
    "        employees_dim.scdensure(row)\n",
    "\n",
    "    # Specify an optional value to return when a lookup fails\n",
    "    employees_dim.defaultidvalue = 0\n",
    "\n",
    "    dw_conn_wrapper.commit()\n",
    "    dw_conn_wrapper.close()\n",
    "def main():\n",
    "    dim_employees_scd2(sourceDatabase, dw_conn_wrapper)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Connect to salesdb (OLTP) and salesdwh (OLT)\n",
    "    sourceDatabase = MySQLdb.connect(database = 'salesdb', user = 'user', password = 'password', port = 42333)\n",
    "    destDatabase = duckdb.connect(r'C:\\Users\\katep\\OneDrive\\Desktop\\DEV-modeling\\assets_scripts\\salesdwh.duckdb') # Change the path if you have your sales duckDB somewhere else\n",
    "    dw_conn_wrapper = pygrametl.ConnectionWrapper(connection = destDatabase)\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f49944c6-5e24-4edf-8ed7-6c107d3ca37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ongoing data load\n",
    "def fact_orders_scd2(sourceDatabase, dw_conn_wrapper):\n",
    "    \"\"\"The function creates the fact table\"\"\"\n",
    "    # Specify the query that will generate the input dataset   \n",
    "    sql = \"select employee_id, concat(employee_first_name,' ', employee_last_name) as employee_name,store_id from employee\"\n",
    "   # Pygrametl will automatically rename columns, in case if names of the input columns are different from the result dataset \n",
    "    name_mapping = 'employee_id','employee_name','store_id'\n",
    "    source = SQLSource(connection = sourceDatabase, query = sql, names = name_mapping)\n",
    "    employees_dim = SlowlyChangingDimension(\n",
    "        name = 'dim_employee_scd2',  # name of the dimensions table in the data warehouse \n",
    "        key = 'employee_sk', # name of the primary key\n",
    "        attributes = ['employee_id', 'valid_from', 'valid_to', 'version', 'employee_name', 'store_id'], #: a sequence of the attribute names in the dimension table. \n",
    "        # Should not include the name of the primary key which is given in the key argument.\n",
    "        lookupatts = ['employee_id'], # a sequence with a subset of the attributes that uniquely identify a dimension members. \n",
    "        fromatt = 'valid_from', # the name of the attribute telling from when the version becomes valid. Default: None\n",
    "        toatt = 'valid_to',\n",
    "        versionatt = 'version') # the name of the attribute telling until when the version is valid. Default: None\n",
    "\n",
    "    for row in source:\n",
    "        employees_dim.scdensure(row)\n",
    "\n",
    "    # Specify an optional value to return when a lookup fails\n",
    "    employees_dim.defaultidvalue = 0\n",
    "\n",
    "    dw_conn_wrapper.commit()\n",
    "    \n",
    "    # Specify the query that will generate the input dataset   \n",
    "    sql2 = \"select order_num, employee_id,customer_id,product_id,sales_channel_id,currency_code,cast(order_quantity as DECIMAL(18, 2)) as order_quantity,cast(total_cost as DECIMAL(18, 2)) as total_cost,cast(total_price as DECIMAL(18, 2)) as total_price,cast(order_date as date) as order_date,cast(ship_date as date) as ship_date,cast(delivery_date as date) as delivery_date,cast(procure_date as date) as procure_date from sales_order\"\n",
    "    # Pygrametl will automatically rename columns, in case if names of the input columns are different from the result dataset \n",
    "    name_mapping2 = 'order_num', 'employee_id','customer_id','product_id','sales_channel_id','currency_code','order_quantity','total_cost','total_price','order_date','ship_date','delivery_date','procure_date'  \n",
    "    source = SQLSource(connection = sourceDatabase, query = sql2, names = name_mapping2)\n",
    "    fact_table = FactTable(\n",
    "        name = 'fact_sales_scd2',  # name of the fact table in the data warehouse \n",
    "        keyrefs = ['order_num', 'customer_id','product_id','sales_channel_id','employee_sk'], # a sequence of attribute names that constitute the primary key of the fact tables \n",
    "        #(i.e., primary keys in the dimension tables that corresponds to foreign keys in the fact table)\n",
    "        measures = ['currency_code','order_quantity','total_cost','total_price','order_date','ship_date','delivery_date','procure_date']\n",
    "        )  \n",
    "    # Specify an optional value to return when a lookup fails\n",
    "    fact_table.defaultidvalue = 0  \n",
    "\n",
    "    # ensure determines whether the row already exists in the database based on ordernum and inserts\n",
    "    # if a fact with identical values for ordernum was already present in the fact table. \n",
    "    # As we specified compare = False, in case the measure value that already exists in the data warehouse is different from the value in the given row, \n",
    "    # the ValueError error is not raised\n",
    "\n",
    "    for row in source:\n",
    "        row['employee_sk'] = employees_dim.lookupasof(row, row['order_date'], (False, True), {'employee_id':'employee_id'})\n",
    "        fact_table.ensure(row, False, {'order_num': 'order_num'}) # lookup returns the keys (employee_sk) based on employee_id\n",
    "\n",
    "    dw_conn_wrapper.commit()\n",
    "    dw_conn_wrapper.close()\n",
    "\n",
    "def main():\n",
    "    fact_orders_scd2(sourceDatabase, dw_conn_wrapper)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Connect to salesdb (OLTP) and salesdwh (OLT)\n",
    "    sourceDatabase = MySQLdb.connect(database = 'salesdb', user = 'user', password = 'password', port = 42333)\n",
    "    destDatabase = duckdb.connect(r'C:\\Users\\katep\\OneDrive\\Desktop\\DEV-modeling\\assets_scripts\\salesdwh.duckdb') # Change the path if you have your sales duckDB somewhere else\n",
    "    dw_conn_wrapper = pygrametl.ConnectionWrapper(connection = destDatabase)\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59c7a5b-6b11-427a-9e66-f8a58cd0bb8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
